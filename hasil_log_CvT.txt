Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
Using image size: 224x224
Loading CIFAR-10 datasets...
Train dataset size: 40000
Validation dataset size: 10000
Creating label encoder...
Number of classes: 10
Classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Label to index mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}

Initializing CvT-13 model...
Loaded CvT-13 pretrained model from Hugging Face
Fine-tuning strategy:
- Frozen: All backbone layers (convolutional token embeddings, transformer stages)
- Trainable: Only classification head (10 classes)
Classifier structure: Linear(in_features=384, out_features=10, bias=True)
CvT(
  (model): CvtForImageClassification(
    (cvt): CvtModel(
      (encoder): CvtEncoder(
        (stages): ModuleList(
          (0): CvtStage(
            (embedding): CvtEmbeddings(
              (convolution_embeddings): CvtConvEmbeddings(
                (projection): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))
                (normalization): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (layers): Sequential(
              (0): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
                        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
                        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
                        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=64, out_features=64, bias=True)
                    (projection_key): Linear(in_features=64, out_features=64, bias=True)
                    (projection_value): Linear(in_features=64, out_features=64, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=64, out_features=64, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=64, out_features=256, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=256, out_features=64, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (layernorm_before): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (1): CvtStage(
            (embedding): CvtEmbeddings(
              (convolution_embeddings): CvtConvEmbeddings(
                (projection): Conv2d(64, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              )
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (layers): Sequential(
              (0): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
                        (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
                        (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
                        (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=192, out_features=192, bias=True)
                    (projection_key): Linear(in_features=192, out_features=192, bias=True)
                    (projection_value): Linear(in_features=192, out_features=192, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=192, out_features=192, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=192, out_features=768, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=768, out_features=192, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              )
              (1): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
                        (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
                        (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
                        (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=192, out_features=192, bias=True)
                    (projection_key): Linear(in_features=192, out_features=192, bias=True)
                    (projection_value): Linear(in_features=192, out_features=192, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=192, out_features=192, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=192, out_features=768, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=768, out_features=192, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (2): CvtStage(
            (embedding): CvtEmbeddings(
              (convolution_embeddings): CvtConvEmbeddings(
                (projection): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (layers): Sequential(
              (0): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (1): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (2): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (3): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (4): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (5): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (6): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (7): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (8): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (9): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
        )
      )
    )
    (layernorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (classifier): Linear(in_features=384, out_features=10, bias=True)
  )
)
Total parameters: 19,616,330
Trainable parameters: 3,850
Frozen parameters: 19,612,480

Starting training with:
- Device: cuda
- Model: CvT-13 (pretrained)
- Image size: 224x224
- Batch size: 128
- Base learning rate: 0.0015
- Warmup epochs: 2
- Number of epochs: 25
- Weight decay: 0.01
- Gradient clipping: 1.0
- Transfer learning: Backbone frozen, head trainable
- Scheduler: Cosine with warmup
--------------------------------------------------------------------------------

Epoch [1/25]
--------------------------------------------------
Batch [0/313], Loss: 2.3434
Batch [10/313], Loss: 2.0523
Batch [20/313], Loss: 1.7436
Batch [30/313], Loss: 1.6484
Batch [40/313], Loss: 1.6232
Batch [50/313], Loss: 1.5943
Batch [60/313], Loss: 1.3355
Batch [70/313], Loss: 1.4095
Batch [80/313], Loss: 1.5300
Batch [90/313], Loss: 1.2012
Batch [100/313], Loss: 1.5182
Batch [110/313], Loss: 1.0491
Batch [120/313], Loss: 1.4307
Batch [130/313], Loss: 1.0702
Batch [140/313], Loss: 1.3686
Batch [150/313], Loss: 1.1278
Batch [160/313], Loss: 1.2217
Batch [170/313], Loss: 1.1843
Batch [180/313], Loss: 1.2502
Batch [190/313], Loss: 1.2887
Batch [200/313], Loss: 1.0810
Batch [210/313], Loss: 1.2101
Batch [220/313], Loss: 1.2551
Batch [230/313], Loss: 1.1811
Batch [240/313], Loss: 1.1783
Batch [250/313], Loss: 1.1436
Batch [260/313], Loss: 1.2646
Batch [270/313], Loss: 1.0308
Batch [280/313], Loss: 1.1581
Batch [290/313], Loss: 1.1664
Batch [300/313], Loss: 1.2688
Batch [310/313], Loss: 1.0584

Epoch 1 Results:
Time: 234.64s
Train - Loss: 1.3341, Acc: 0.5452, F1: 0.5443, Precision: 0.5485, Recall: 0.5452
Val   - Loss: 0.8139, Acc: 0.7295, F1: 0.7276, Precision: 0.7287, Recall: 0.7295
New best model saved! Validation accuracy: 0.7295
--------------------------------------------------------------------------------

Epoch [2/25]
--------------------------------------------------
Batch [0/313], Loss: 1.3432
Batch [10/313], Loss: 1.1226
Batch [20/313], Loss: 1.1330
Batch [30/313], Loss: 1.0501
Batch [40/313], Loss: 1.1650
Batch [50/313], Loss: 1.2026
Batch [60/313], Loss: 1.0559
Batch [70/313], Loss: 1.1958
Batch [80/313], Loss: 1.1315
Batch [90/313], Loss: 1.2022
Batch [100/313], Loss: 1.1398
Batch [110/313], Loss: 1.0439
Batch [120/313], Loss: 1.1804
Batch [130/313], Loss: 1.0477
Batch [140/313], Loss: 1.0421
Batch [150/313], Loss: 1.0465
Batch [160/313], Loss: 1.0749
Batch [170/313], Loss: 0.9179
Batch [180/313], Loss: 1.1155
Batch [190/313], Loss: 1.0093
Batch [200/313], Loss: 1.0935
Batch [210/313], Loss: 1.0411
Batch [220/313], Loss: 1.0073
Batch [230/313], Loss: 1.1280
Batch [240/313], Loss: 0.9953
Batch [250/313], Loss: 1.0407
Batch [260/313], Loss: 1.1170
Batch [270/313], Loss: 1.2049
Batch [280/313], Loss: 1.2268
Batch [290/313], Loss: 1.2038
Batch [300/313], Loss: 1.1271
Batch [310/313], Loss: 1.0689

Epoch 2 Results:
Time: 234.87s
Train - Loss: 1.1141, Acc: 0.6001, F1: 0.6011, Precision: 0.6030, Recall: 0.6001
Val   - Loss: 0.7337, Acc: 0.7467, F1: 0.7445, Precision: 0.7447, Recall: 0.7467
New best model saved! Validation accuracy: 0.7467
--------------------------------------------------------------------------------

Epoch [3/25]
--------------------------------------------------
Batch [0/313], Loss: 0.9429
Batch [10/313], Loss: 1.0542
Batch [20/313], Loss: 1.1362
Batch [30/313], Loss: 1.1328
Batch [40/313], Loss: 1.0667
Batch [50/313], Loss: 0.9983
Batch [60/313], Loss: 1.0595
Batch [70/313], Loss: 1.0628
Batch [80/313], Loss: 1.0891
Batch [90/313], Loss: 1.1623
Batch [100/313], Loss: 1.0737
Batch [110/313], Loss: 1.0214
Batch [120/313], Loss: 0.9878
Batch [130/313], Loss: 1.1680
Batch [140/313], Loss: 0.9674
Batch [150/313], Loss: 1.0276
Batch [160/313], Loss: 1.2132
Batch [170/313], Loss: 1.0111
Batch [180/313], Loss: 1.0950
Batch [190/313], Loss: 0.9863
Batch [200/313], Loss: 1.1374
Batch [210/313], Loss: 1.1775
Batch [220/313], Loss: 1.0335
Batch [230/313], Loss: 0.9547
Batch [240/313], Loss: 0.8514
Batch [250/313], Loss: 1.1229
Batch [260/313], Loss: 1.0272
Batch [270/313], Loss: 1.0332
Batch [280/313], Loss: 1.0613
Batch [290/313], Loss: 1.1357
Batch [300/313], Loss: 1.0674
Batch [310/313], Loss: 1.0921

Epoch 3 Results:
Time: 241.46s
Train - Loss: 1.0682, Acc: 0.6154, F1: 0.6150, Precision: 0.6152, Recall: 0.6154
Val   - Loss: 0.7110, Acc: 0.7532, F1: 0.7518, Precision: 0.7521, Recall: 0.7532
New best model saved! Validation accuracy: 0.7532
--------------------------------------------------------------------------------

Epoch [4/25]
--------------------------------------------------
Batch [0/313], Loss: 1.0798
Batch [10/313], Loss: 1.0859
Batch [20/313], Loss: 1.0855
Batch [30/313], Loss: 1.1504
Batch [40/313], Loss: 1.0155
Batch [50/313], Loss: 1.2047
Batch [60/313], Loss: 1.2103
Batch [70/313], Loss: 1.0969
Batch [80/313], Loss: 1.2324
Batch [90/313], Loss: 1.1126
Batch [100/313], Loss: 0.8624
Batch [110/313], Loss: 0.9753
Batch [120/313], Loss: 1.1439
Batch [130/313], Loss: 1.0909
Batch [140/313], Loss: 1.2277
Batch [150/313], Loss: 1.0694
Batch [160/313], Loss: 1.0334
Batch [170/313], Loss: 1.1232
Batch [180/313], Loss: 1.0188
Batch [190/313], Loss: 1.1017
Batch [200/313], Loss: 0.8445
Batch [210/313], Loss: 0.9624
Batch [220/313], Loss: 0.9899
Batch [230/313], Loss: 1.1498
Batch [240/313], Loss: 0.9884
Batch [250/313], Loss: 1.1903
Batch [260/313], Loss: 1.0427
Batch [270/313], Loss: 1.0292
Batch [280/313], Loss: 1.1882
Batch [290/313], Loss: 0.9122
Batch [300/313], Loss: 0.8991
Batch [310/313], Loss: 0.8902

Epoch 4 Results:
Time: 242.46s
Train - Loss: 1.0473, Acc: 0.6181, F1: 0.6183, Precision: 0.6192, Recall: 0.6181
Val   - Loss: 0.6884, Acc: 0.7610, F1: 0.7599, Precision: 0.7597, Recall: 0.7610
New best model saved! Validation accuracy: 0.7610
--------------------------------------------------------------------------------

Epoch [5/25]
--------------------------------------------------
Batch [0/313], Loss: 0.9394
Batch [10/313], Loss: 1.0105
Batch [20/313], Loss: 0.9668
Batch [30/313], Loss: 1.1083
Batch [40/313], Loss: 1.0757
Batch [50/313], Loss: 0.9210
Batch [60/313], Loss: 1.1652
Batch [70/313], Loss: 0.9193
Batch [80/313], Loss: 0.9331
Batch [90/313], Loss: 1.1896
Batch [100/313], Loss: 0.9994
Batch [110/313], Loss: 1.0243
Batch [120/313], Loss: 0.8985
Batch [130/313], Loss: 0.9623
Batch [140/313], Loss: 1.0856
Batch [150/313], Loss: 1.1431
Batch [160/313], Loss: 0.8247
Batch [170/313], Loss: 0.8116
Batch [180/313], Loss: 0.9298
Batch [190/313], Loss: 1.0919
Batch [200/313], Loss: 1.0397
Batch [210/313], Loss: 1.0868
Batch [220/313], Loss: 1.0025
Batch [230/313], Loss: 0.9687
Batch [240/313], Loss: 0.9414
Batch [250/313], Loss: 0.9848
Batch [260/313], Loss: 0.9977
Batch [270/313], Loss: 1.0458
Batch [280/313], Loss: 0.9745
Batch [290/313], Loss: 1.0458
Batch [300/313], Loss: 0.8932
Batch [310/313], Loss: 0.8302

Epoch 5 Results:
Time: 251.81s
Train - Loss: 1.0292, Acc: 0.6258, F1: 0.6255, Precision: 0.6263, Recall: 0.6258
Val   - Loss: 0.6844, Acc: 0.7638, F1: 0.7626, Precision: 0.7631, Recall: 0.7638
New best model saved! Validation accuracy: 0.7638
--------------------------------------------------------------------------------

Epoch [6/25]
--------------------------------------------------
Batch [0/313], Loss: 0.8407
Batch [10/313], Loss: 0.9972
Batch [20/313], Loss: 0.9168
Batch [30/313], Loss: 0.9907
Batch [40/313], Loss: 1.0554
Batch [50/313], Loss: 0.9547
Batch [60/313], Loss: 1.0752
Batch [70/313], Loss: 1.0715
Batch [80/313], Loss: 0.9036
Batch [90/313], Loss: 0.8434
Batch [100/313], Loss: 0.8362
Batch [110/313], Loss: 0.9557
Batch [120/313], Loss: 1.1036
Batch [130/313], Loss: 1.0053
Batch [140/313], Loss: 1.2415
Batch [150/313], Loss: 0.9113
Batch [160/313], Loss: 1.0351
Batch [170/313], Loss: 1.0535
Batch [180/313], Loss: 1.1115
Batch [190/313], Loss: 0.9322
Batch [200/313], Loss: 0.8536
Batch [210/313], Loss: 1.0100
Batch [220/313], Loss: 0.9696
Batch [230/313], Loss: 1.1781
Batch [240/313], Loss: 1.0206
Batch [250/313], Loss: 0.9121
Batch [260/313], Loss: 1.0854
Batch [270/313], Loss: 1.0567
Batch [280/313], Loss: 0.9121
Batch [290/313], Loss: 0.8812
Batch [300/313], Loss: 0.9488
Batch [310/313], Loss: 1.1923

Epoch 6 Results:
Time: 259.13s
Train - Loss: 1.0196, Acc: 0.6290, F1: 0.6292, Precision: 0.6308, Recall: 0.6290
Val   - Loss: 0.6776, Acc: 0.7646, F1: 0.7639, Precision: 0.7645, Recall: 0.7646
New best model saved! Validation accuracy: 0.7646
--------------------------------------------------------------------------------

Epoch [7/25]
--------------------------------------------------
Batch [0/313], Loss: 1.1162
Batch [10/313], Loss: 0.9264
Batch [20/313], Loss: 0.9273
Batch [30/313], Loss: 1.0833
Batch [40/313], Loss: 0.9565
Batch [50/313], Loss: 0.9599
Batch [60/313], Loss: 0.9933
Batch [70/313], Loss: 0.9084
Batch [80/313], Loss: 1.1434
Batch [90/313], Loss: 1.0465
Batch [100/313], Loss: 1.0083
Batch [110/313], Loss: 1.1432
Batch [120/313], Loss: 1.0666
Batch [130/313], Loss: 0.9886
Batch [140/313], Loss: 1.1332
Batch [150/313], Loss: 1.0979
Batch [160/313], Loss: 1.2366
Batch [170/313], Loss: 1.1545
Batch [180/313], Loss: 1.0116
Batch [190/313], Loss: 1.1662
Batch [200/313], Loss: 0.9945
Batch [210/313], Loss: 1.0377
Batch [220/313], Loss: 1.1804
Batch [230/313], Loss: 1.0265
Batch [240/313], Loss: 1.0245
Batch [250/313], Loss: 1.0912
Batch [260/313], Loss: 1.0436
Batch [270/313], Loss: 0.9926
Batch [280/313], Loss: 1.0984
Batch [290/313], Loss: 1.1236
Batch [300/313], Loss: 0.9771
Batch [310/313], Loss: 1.0004

Epoch 7 Results:
Time: 261.66s
Train - Loss: 1.0161, Acc: 0.6277, F1: 0.6279, Precision: 0.6295, Recall: 0.6277
Val   - Loss: 0.6763, Acc: 0.7629, F1: 0.7615, Precision: 0.7619, Recall: 0.7629
No improvement in validation accuracy for 1 epoch(s)
--------------------------------------------------------------------------------

Epoch [8/25]
--------------------------------------------------
Batch [0/313], Loss: 0.9586
Batch [10/313], Loss: 1.0027
Batch [20/313], Loss: 1.0361
Batch [30/313], Loss: 0.9485
Batch [40/313], Loss: 1.0150
Batch [50/313], Loss: 1.0505
Batch [60/313], Loss: 0.9705
Batch [70/313], Loss: 0.9008
Batch [80/313], Loss: 0.9684
Batch [90/313], Loss: 1.0224
Batch [100/313], Loss: 0.9834
Batch [110/313], Loss: 1.0252
Batch [120/313], Loss: 0.8589
Batch [130/313], Loss: 0.9612
Batch [140/313], Loss: 0.8687
Batch [150/313], Loss: 1.0998
Batch [160/313], Loss: 1.2473
Batch [170/313], Loss: 1.1410
Batch [180/313], Loss: 0.8790
Batch [190/313], Loss: 1.0118
Batch [200/313], Loss: 1.0099
Batch [210/313], Loss: 1.1562
Batch [220/313], Loss: 1.0396
Batch [230/313], Loss: 1.0508
Batch [240/313], Loss: 1.1347
Batch [250/313], Loss: 1.0186
Batch [260/313], Loss: 1.1227
Batch [270/313], Loss: 0.8822
Batch [280/313], Loss: 1.1320
Batch [290/313], Loss: 0.8964
Batch [300/313], Loss: 0.9269
Batch [310/313], Loss: 0.9082

Epoch 8 Results:
Time: 263.03s
Train - Loss: 1.0094, Acc: 0.6313, F1: 0.6327, Precision: 0.6357, Recall: 0.6313
Val   - Loss: 0.6677, Acc: 0.7689, F1: 0.7677, Precision: 0.7680, Recall: 0.7689
New best model saved! Validation accuracy: 0.7689
--------------------------------------------------------------------------------

Epoch [9/25]
--------------------------------------------------
Batch [0/313], Loss: 1.0918
Batch [10/313], Loss: 1.0737
Batch [20/313], Loss: 1.0005
Batch [30/313], Loss: 1.0879
Batch [40/313], Loss: 0.9562
Batch [50/313], Loss: 1.0150
Batch [60/313], Loss: 1.0665
Batch [70/313], Loss: 0.9706
Batch [80/313], Loss: 0.9735
Batch [90/313], Loss: 0.8910
Batch [100/313], Loss: 1.0661
Batch [110/313], Loss: 0.9673
Batch [120/313], Loss: 0.9045
Batch [130/313], Loss: 0.9394
Batch [140/313], Loss: 1.0282
Batch [150/313], Loss: 0.9484
Batch [160/313], Loss: 0.9704
Batch [170/313], Loss: 1.1217
Batch [180/313], Loss: 0.8850
Batch [190/313], Loss: 0.7356
Batch [200/313], Loss: 0.9484
Batch [210/313], Loss: 1.0105
Batch [220/313], Loss: 0.8698
Batch [230/313], Loss: 0.8931
Batch [240/313], Loss: 0.9623
Batch [250/313], Loss: 1.1755
Batch [260/313], Loss: 0.8652
Batch [270/313], Loss: 1.1171
Batch [280/313], Loss: 1.1504
Batch [290/313], Loss: 1.0079
Batch [300/313], Loss: 0.9249
Batch [310/313], Loss: 0.9142

Epoch 9 Results:
Time: 264.77s
Train - Loss: 1.0101, Acc: 0.6332, F1: 0.6337, Precision: 0.6351, Recall: 0.6332
Val   - Loss: 0.6646, Acc: 0.7702, F1: 0.7693, Precision: 0.7693, Recall: 0.7702
New best model saved! Validation accuracy: 0.7702
--------------------------------------------------------------------------------

Epoch [10/25]
--------------------------------------------------
