Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU
Using image size: 224x224
Loading CIFAR-10 datasets...
Train dataset size: 40000
Validation dataset size: 10000
Creating label encoder...
Number of classes: 10
Classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Label to index mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}

Initializing CvT-13 model...
Loaded CvT-13 pretrained model from Hugging Face
Fine-tuning strategy:
- Frozen: All backbone layers (convolutional token embeddings, transformer stages)
- Trainable: Only classification head (10 classes)
Classifier structure: Linear(in_features=384, out_features=10, bias=True)
CvT(
  (model): CvtForImageClassification(
    (cvt): CvtModel(
      (encoder): CvtEncoder(
        (stages): ModuleList(
          (0): CvtStage(
            (embedding): CvtEmbeddings(
              (convolution_embeddings): CvtConvEmbeddings(
                (projection): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))
                (normalization): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (layers): Sequential(
              (0): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
                        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
                        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
                        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=64, out_features=64, bias=True)
                    (projection_key): Linear(in_features=64, out_features=64, bias=True)
                    (projection_value): Linear(in_features=64, out_features=64, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=64, out_features=64, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=64, out_features=256, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=256, out_features=64, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (layernorm_before): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (1): CvtStage(
            (embedding): CvtEmbeddings(
              (convolution_embeddings): CvtConvEmbeddings(
                (projection): Conv2d(64, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              )
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (layers): Sequential(
              (0): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
                        (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
                        (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
                        (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=192, out_features=192, bias=True)
                    (projection_key): Linear(in_features=192, out_features=192, bias=True)
                    (projection_value): Linear(in_features=192, out_features=192, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=192, out_features=192, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=192, out_features=768, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=768, out_features=192, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              )
              (1): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
                        (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
                        (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
                        (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=192, out_features=192, bias=True)
                    (projection_key): Linear(in_features=192, out_features=192, bias=True)
                    (projection_value): Linear(in_features=192, out_features=192, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=192, out_features=192, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=192, out_features=768, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=768, out_features=192, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): Identity()
                (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (2): CvtStage(
            (embedding): CvtEmbeddings(
              (convolution_embeddings): CvtConvEmbeddings(
                (projection): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
                (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (dropout): Dropout(p=0.0, inplace=False)
            )
            (layers): Sequential(
              (0): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (1): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (2): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (3): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (4): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (5): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (6): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (7): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (8): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
              (9): CvtLayer(
                (attention): CvtAttention(
                  (attention): CvtSelfAttention(
                    (convolution_projection_query): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_key): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (convolution_projection_value): CvtSelfAttentionProjection(
                      (convolution_projection): CvtSelfAttentionConvProjection(
                        (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
                        (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                      )
                      (linear_projection): CvtSelfAttentionLinearProjection()
                    )
                    (projection_query): Linear(in_features=384, out_features=384, bias=True)
                    (projection_key): Linear(in_features=384, out_features=384, bias=True)
                    (projection_value): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                  (output): CvtSelfOutput(
                    (dense): Linear(in_features=384, out_features=384, bias=True)
                    (dropout): Dropout(p=0.0, inplace=False)
                  )
                )
                (intermediate): CvtIntermediate(
                  (dense): Linear(in_features=384, out_features=1536, bias=True)
                  (activation): GELU(approximate='none')
                )
                (output): CvtOutput(
                  (dense): Linear(in_features=1536, out_features=384, bias=True)
                  (dropout): Dropout(p=0.0, inplace=False)
                )
                (drop_path): CvtDropPath(p=0.02222222276031971)
                (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
        )
      )
    )
    (layernorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (classifier): Linear(in_features=384, out_features=10, bias=True)
  )
)
Total parameters: 19,616,330
Trainable parameters: 3,850
Frozen parameters: 19,612,480

Starting training with:
- Device: cuda
- Model: CvT-13 (pretrained)
- Image size: 224x224
- Batch size: 128
- Base learning rate: 0.0015
- Warmup epochs: 2
- Number of epochs: 25
- Weight decay: 0.01
- Gradient clipping: 1.0
- Transfer learning: Backbone frozen, head trainable
- Scheduler: Cosine with warmup
--------------------------------------------------------------------------------

Epoch [1/25]
--------------------------------------------------
Batch [0/313], Loss: 2.3434
Batch [10/313], Loss: 2.0523
Batch [20/313], Loss: 1.7436
Batch [30/313], Loss: 1.6484
Batch [40/313], Loss: 1.6232
Batch [50/313], Loss: 1.5943
Batch [60/313], Loss: 1.3355
Batch [70/313], Loss: 1.4095
Batch [80/313], Loss: 1.5300
Batch [90/313], Loss: 1.2012
Batch [100/313], Loss: 1.5182
Batch [110/313], Loss: 1.0491
Batch [120/313], Loss: 1.4307
Batch [130/313], Loss: 1.0702
Batch [140/313], Loss: 1.3686
Batch [150/313], Loss: 1.1278
Batch [160/313], Loss: 1.2217
Batch [170/313], Loss: 1.1843
Batch [180/313], Loss: 1.2502
Batch [190/313], Loss: 1.2887
Batch [200/313], Loss: 1.0810
Batch [210/313], Loss: 1.2101
Batch [220/313], Loss: 1.2551
Batch [230/313], Loss: 1.1811
Batch [240/313], Loss: 1.1783
Batch [250/313], Loss: 1.1436
Batch [260/313], Loss: 1.2646
Batch [270/313], Loss: 1.0308
Batch [280/313], Loss: 1.1581
Batch [290/313], Loss: 1.1664
Batch [300/313], Loss: 1.2688
Batch [310/313], Loss: 1.0584

Epoch 1 Results:
Time: 234.64s
Train - Loss: 1.3341, Acc: 0.5452, F1: 0.5443, Precision: 0.5485, Recall: 0.5452
Val   - Loss: 0.8139, Acc: 0.7295, F1: 0.7276, Precision: 0.7287, Recall: 0.7295
New best model saved! Validation accuracy: 0.7295
--------------------------------------------------------------------------------

Epoch [2/25]
--------------------------------------------------
Batch [0/313], Loss: 1.3432
Batch [10/313], Loss: 1.1226
Batch [20/313], Loss: 1.1330
Batch [30/313], Loss: 1.0501
Batch [40/313], Loss: 1.1650
Batch [50/313], Loss: 1.2026
Batch [60/313], Loss: 1.0559
Batch [70/313], Loss: 1.1958
Batch [80/313], Loss: 1.1315
Batch [90/313], Loss: 1.2022
Batch [100/313], Loss: 1.1398
Batch [110/313], Loss: 1.0439
Batch [120/313], Loss: 1.1804
Batch [130/313], Loss: 1.0477
Batch [140/313], Loss: 1.0421
Batch [150/313], Loss: 1.0465
Batch [160/313], Loss: 1.0749
Batch [170/313], Loss: 0.9179
Batch [180/313], Loss: 1.1155
Batch [190/313], Loss: 1.0093
Batch [200/313], Loss: 1.0935
Batch [210/313], Loss: 1.0411
Batch [220/313], Loss: 1.0073
Batch [230/313], Loss: 1.1280
Batch [240/313], Loss: 0.9953
Batch [250/313], Loss: 1.0407
Batch [260/313], Loss: 1.1170
Batch [270/313], Loss: 1.2049
Batch [280/313], Loss: 1.2268
Batch [290/313], Loss: 1.2038
Batch [300/313], Loss: 1.1271
Batch [310/313], Loss: 1.0689

Epoch 2 Results:
Time: 234.87s
Train - Loss: 1.1141, Acc: 0.6001, F1: 0.6011, Precision: 0.6030, Recall: 0.6001
Val   - Loss: 0.7337, Acc: 0.7467, F1: 0.7445, Precision: 0.7447, Recall: 0.7467
New best model saved! Validation accuracy: 0.7467
--------------------------------------------------------------------------------

Epoch [3/25]
--------------------------------------------------
Batch [0/313], Loss: 0.9429
Batch [10/313], Loss: 1.0542
Batch [20/313], Loss: 1.1362
Batch [30/313], Loss: 1.1328
Batch [40/313], Loss: 1.0667
Batch [50/313], Loss: 0.9983
Batch [60/313], Loss: 1.0595
Batch [70/313], Loss: 1.0628
Batch [80/313], Loss: 1.0891
Batch [90/313], Loss: 1.1623
Batch [100/313], Loss: 1.0737
Batch [110/313], Loss: 1.0214
Batch [120/313], Loss: 0.9878
Batch [130/313], Loss: 1.1680
Batch [140/313], Loss: 0.9674
Batch [150/313], Loss: 1.0276
Batch [160/313], Loss: 1.2132
Batch [170/313], Loss: 1.0111
Batch [180/313], Loss: 1.0950
Batch [190/313], Loss: 0.9863
Batch [200/313], Loss: 1.1374
Batch [210/313], Loss: 1.1775
Batch [220/313], Loss: 1.0335
Batch [230/313], Loss: 0.9547
Batch [240/313], Loss: 0.8514
Batch [250/313], Loss: 1.1229
Batch [260/313], Loss: 1.0272
Batch [270/313], Loss: 1.0332
Batch [280/313], Loss: 1.0613
Batch [290/313], Loss: 1.1357
Batch [300/313], Loss: 1.0674
Batch [310/313], Loss: 1.0921

Epoch 3 Results:
Time: 241.46s
Train - Loss: 1.0682, Acc: 0.6154, F1: 0.6150, Precision: 0.6152, Recall: 0.6154
Val   - Loss: 0.7110, Acc: 0.7532, F1: 0.7518, Precision: 0.7521, Recall: 0.7532
New best model saved! Validation accuracy: 0.7532
--------------------------------------------------------------------------------

Epoch [4/25]
--------------------------------------------------
Batch [0/313], Loss: 1.0798
Batch [10/313], Loss: 1.0859
Batch [20/313], Loss: 1.0855
Batch [30/313], Loss: 1.1504
Batch [40/313], Loss: 1.0155
Batch [50/313], Loss: 1.2047
Batch [60/313], Loss: 1.2103
Batch [70/313], Loss: 1.0969
Batch [80/313], Loss: 1.2324
Batch [90/313], Loss: 1.1126
Batch [100/313], Loss: 0.8624
Batch [110/313], Loss: 0.9753
Batch [120/313], Loss: 1.1439
Batch [130/313], Loss: 1.0909
Batch [140/313], Loss: 1.2277
Batch [150/313], Loss: 1.0694
Batch [160/313], Loss: 1.0334
Batch [170/313], Loss: 1.1232
Batch [180/313], Loss: 1.0188
Batch [190/313], Loss: 1.1017
Batch [200/313], Loss: 0.8445
Batch [210/313], Loss: 0.9624
Batch [220/313], Loss: 0.9899
Batch [230/313], Loss: 1.1498
Batch [240/313], Loss: 0.9884
Batch [250/313], Loss: 1.1903
Batch [260/313], Loss: 1.0427
Batch [270/313], Loss: 1.0292
Batch [280/313], Loss: 1.1882
Batch [290/313], Loss: 0.9122
Batch [300/313], Loss: 0.8991
Batch [310/313], Loss: 0.8902

Epoch 4 Results:
Time: 242.46s
Train - Loss: 1.0473, Acc: 0.6181, F1: 0.6183, Precision: 0.6192, Recall: 0.6181
Val   - Loss: 0.6884, Acc: 0.7610, F1: 0.7599, Precision: 0.7597, Recall: 0.7610
New best model saved! Validation accuracy: 0.7610
--------------------------------------------------------------------------------

Epoch [5/25]
--------------------------------------------------
Batch [0/313], Loss: 0.9394
Batch [10/313], Loss: 1.0105
Batch [20/313], Loss: 0.9668
Batch [30/313], Loss: 1.1083
Batch [40/313], Loss: 1.0757
Batch [50/313], Loss: 0.9210
Batch [60/313], Loss: 1.1652
Batch [70/313], Loss: 0.9193
Batch [80/313], Loss: 0.9331
Batch [90/313], Loss: 1.1896
Batch [100/313], Loss: 0.9994
Batch [110/313], Loss: 1.0243
Batch [120/313], Loss: 0.8985
Batch [130/313], Loss: 0.9623
Batch [140/313], Loss: 1.0856
Batch [150/313], Loss: 1.1431
Batch [160/313], Loss: 0.8247
Batch [170/313], Loss: 0.8116
Batch [180/313], Loss: 0.9298
Batch [190/313], Loss: 1.0919
Batch [200/313], Loss: 1.0397
Batch [210/313], Loss: 1.0868
Batch [220/313], Loss: 1.0025
Batch [230/313], Loss: 0.9687
Batch [240/313], Loss: 0.9414
Batch [250/313], Loss: 0.9848
Batch [260/313], Loss: 0.9977
Batch [270/313], Loss: 1.0458
Batch [280/313], Loss: 0.9745
Batch [290/313], Loss: 1.0458
Batch [300/313], Loss: 0.8932
Batch [310/313], Loss: 0.8302

Epoch 5 Results:
Time: 251.81s
Train - Loss: 1.0292, Acc: 0.6258, F1: 0.6255, Precision: 0.6263, Recall: 0.6258
Val   - Loss: 0.6844, Acc: 0.7638, F1: 0.7626, Precision: 0.7631, Recall: 0.7638
New best model saved! Validation accuracy: 0.7638
--------------------------------------------------------------------------------

Epoch [6/25]
--------------------------------------------------
Batch [0/313], Loss: 0.8407
Batch [10/313], Loss: 0.9972
Batch [20/313], Loss: 0.9168
Batch [30/313], Loss: 0.9907
Batch [40/313], Loss: 1.0554
Batch [50/313], Loss: 0.9547
Batch [60/313], Loss: 1.0752
Batch [70/313], Loss: 1.0715
Batch [80/313], Loss: 0.9036
Batch [90/313], Loss: 0.8434
Batch [100/313], Loss: 0.8362
Batch [110/313], Loss: 0.9557
Batch [120/313], Loss: 1.1036
Batch [130/313], Loss: 1.0053
Batch [140/313], Loss: 1.2415
Batch [150/313], Loss: 0.9113
Batch [160/313], Loss: 1.0351
Batch [170/313], Loss: 1.0535
Batch [180/313], Loss: 1.1115
Batch [190/313], Loss: 0.9322
Batch [200/313], Loss: 0.8536
Batch [210/313], Loss: 1.0100
Batch [220/313], Loss: 0.9696
Batch [230/313], Loss: 1.1781
Batch [240/313], Loss: 1.0206
Batch [250/313], Loss: 0.9121
Batch [260/313], Loss: 1.0854
Batch [270/313], Loss: 1.0567
Batch [280/313], Loss: 0.9121
Batch [290/313], Loss: 0.8812
Batch [300/313], Loss: 0.9488
Batch [310/313], Loss: 1.1923

Epoch 6 Results:
Time: 259.13s
Train - Loss: 1.0196, Acc: 0.6290, F1: 0.6292, Precision: 0.6308, Recall: 0.6290
Val   - Loss: 0.6776, Acc: 0.7646, F1: 0.7639, Precision: 0.7645, Recall: 0.7646
New best model saved! Validation accuracy: 0.7646
--------------------------------------------------------------------------------

Epoch [7/25]
--------------------------------------------------
Batch [0/313], Loss: 1.1162
Batch [10/313], Loss: 0.9264
Batch [20/313], Loss: 0.9273
Batch [30/313], Loss: 1.0833
Batch [40/313], Loss: 0.9565
Batch [50/313], Loss: 0.9599
Batch [60/313], Loss: 0.9933
Batch [70/313], Loss: 0.9084
Batch [80/313], Loss: 1.1434
Batch [90/313], Loss: 1.0465
Batch [100/313], Loss: 1.0083
Batch [110/313], Loss: 1.1432
Batch [120/313], Loss: 1.0666
Batch [130/313], Loss: 0.9886
Batch [140/313], Loss: 1.1332
Batch [150/313], Loss: 1.0979
Batch [160/313], Loss: 1.2366
Batch [170/313], Loss: 1.1545
Batch [180/313], Loss: 1.0116
Batch [190/313], Loss: 1.1662
Batch [200/313], Loss: 0.9945
Batch [210/313], Loss: 1.0377
Batch [220/313], Loss: 1.1804
Batch [230/313], Loss: 1.0265
Batch [240/313], Loss: 1.0245
Batch [250/313], Loss: 1.0912
Batch [260/313], Loss: 1.0436
Batch [270/313], Loss: 0.9926
Batch [280/313], Loss: 1.0984
Batch [290/313], Loss: 1.1236
Batch [300/313], Loss: 0.9771
Batch [310/313], Loss: 1.0004

Epoch 7 Results:
Time: 261.66s
Train - Loss: 1.0161, Acc: 0.6277, F1: 0.6279, Precision: 0.6295, Recall: 0.6277
Val   - Loss: 0.6763, Acc: 0.7629, F1: 0.7615, Precision: 0.7619, Recall: 0.7629
No improvement in validation accuracy for 1 epoch(s)
--------------------------------------------------------------------------------

Epoch [8/25]
--------------------------------------------------
Batch [0/313], Loss: 0.9586
Batch [10/313], Loss: 1.0027
Batch [20/313], Loss: 1.0361
Batch [30/313], Loss: 0.9485
Batch [40/313], Loss: 1.0150
Batch [50/313], Loss: 1.0505
Batch [60/313], Loss: 0.9705
Batch [70/313], Loss: 0.9008
Batch [80/313], Loss: 0.9684
Batch [90/313], Loss: 1.0224
Batch [100/313], Loss: 0.9834
Batch [110/313], Loss: 1.0252
Batch [120/313], Loss: 0.8589
Batch [130/313], Loss: 0.9612
Batch [140/313], Loss: 0.8687
Batch [150/313], Loss: 1.0998
Batch [160/313], Loss: 1.2473
Batch [170/313], Loss: 1.1410
Batch [180/313], Loss: 0.8790
Batch [190/313], Loss: 1.0118
Batch [200/313], Loss: 1.0099
Batch [210/313], Loss: 1.1562
Batch [220/313], Loss: 1.0396
Batch [230/313], Loss: 1.0508
Batch [240/313], Loss: 1.1347
Batch [250/313], Loss: 1.0186
Batch [260/313], Loss: 1.1227
Batch [270/313], Loss: 0.8822
Batch [280/313], Loss: 1.1320
Batch [290/313], Loss: 0.8964
Batch [300/313], Loss: 0.9269
Batch [310/313], Loss: 0.9082

Epoch 8 Results:
Time: 263.03s
Train - Loss: 1.0094, Acc: 0.6313, F1: 0.6327, Precision: 0.6357, Recall: 0.6313
Val   - Loss: 0.6677, Acc: 0.7689, F1: 0.7677, Precision: 0.7680, Recall: 0.7689
New best model saved! Validation accuracy: 0.7689
--------------------------------------------------------------------------------

Epoch [9/25]
--------------------------------------------------
Batch [0/313], Loss: 1.0918
Batch [10/313], Loss: 1.0737
Batch [20/313], Loss: 1.0005
Batch [30/313], Loss: 1.0879
Batch [40/313], Loss: 0.9562
Batch [50/313], Loss: 1.0150
Batch [60/313], Loss: 1.0665
Batch [70/313], Loss: 0.9706
Batch [80/313], Loss: 0.9735
Batch [90/313], Loss: 0.8910
Batch [100/313], Loss: 1.0661
Batch [110/313], Loss: 0.9673
Batch [120/313], Loss: 0.9045
Batch [130/313], Loss: 0.9394
Batch [140/313], Loss: 1.0282
Batch [150/313], Loss: 0.9484
Batch [160/313], Loss: 0.9704
Batch [170/313], Loss: 1.1217
Batch [180/313], Loss: 0.8850
Batch [190/313], Loss: 0.7356
Batch [200/313], Loss: 0.9484
Batch [210/313], Loss: 1.0105
Batch [220/313], Loss: 0.8698
Batch [230/313], Loss: 0.8931
Batch [240/313], Loss: 0.9623
Batch [250/313], Loss: 1.1755
Batch [260/313], Loss: 0.8652
Batch [270/313], Loss: 1.1171
Batch [280/313], Loss: 1.1504
Batch [290/313], Loss: 1.0079
Batch [300/313], Loss: 0.9249
Batch [310/313], Loss: 0.9142

Epoch 9 Results:
Time: 264.77s
Train - Loss: 1.0101, Acc: 0.6332, F1: 0.6337, Precision: 0.6351, Recall: 0.6332
Val   - Loss: 0.6646, Acc: 0.7702, F1: 0.7693, Precision: 0.7693, Recall: 0.7702
New best model saved! Validation accuracy: 0.7702
--------------------------------------------------------------------------------

Epoch [10/25]
--------------------------------------------------
Batch [0/313], Loss: 1.0238
Batch [10/313], Loss: 0.9226
Batch [20/313], Loss: 0.8936
Batch [30/313], Loss: 0.9596
Batch [40/313], Loss: 1.0094
Batch [50/313], Loss: 1.0161
Batch [60/313], Loss: 1.0181
Batch [70/313], Loss: 0.9687
Batch [80/313], Loss: 0.8973
Batch [90/313], Loss: 0.8617
Batch [100/313], Loss: 0.9325
Batch [110/313], Loss: 0.9698
Batch [120/313], Loss: 1.1191
Batch [130/313], Loss: 0.9156
Batch [140/313], Loss: 1.0694
Batch [150/313], Loss: 0.8388
Batch [160/313], Loss: 1.0895
Batch [170/313], Loss: 0.9366
Batch [180/313], Loss: 0.9099
Batch [190/313], Loss: 0.7881
Batch [200/313], Loss: 0.8959
Batch [210/313], Loss: 0.9323
Batch [220/313], Loss: 0.9041
Batch [230/313], Loss: 1.0868
Batch [240/313], Loss: 0.8114
Batch [250/313], Loss: 0.9731
Batch [260/313], Loss: 1.0689
Batch [270/313], Loss: 0.9656
Batch [280/313], Loss: 1.0356
Batch [290/313], Loss: 1.0106
Batch [300/313], Loss: 1.1193
Batch [310/313], Loss: 1.0878

Epoch 10 Results:
Time: 264.11s
Train - Loss: 1.0033, Acc: 0.6328, F1: 0.6339, Precision: 0.6363, Recall: 0.6328
Val   - Loss: 0.6649, Acc: 0.7696, F1: 0.7684, Precision: 0.7686, Recall: 0.7696
No improvement in validation accuracy for 1 epoch(s)
--------------------------------------------------------------------------------

Epoch [11/25]
--------------------------------------------------
Batch [0/313], Loss: 0.9517
Batch [10/313], Loss: 0.8534
Batch [20/313], Loss: 0.8368
Batch [30/313], Loss: 0.9893
Batch [40/313], Loss: 0.7861
Batch [50/313], Loss: 0.9667
Batch [60/313], Loss: 1.1758
Batch [70/313], Loss: 0.9013
Batch [80/313], Loss: 1.0135
Batch [90/313], Loss: 1.0834
Batch [100/313], Loss: 0.9107
Batch [110/313], Loss: 1.0321
Batch [120/313], Loss: 1.0218
Batch [130/313], Loss: 0.9472
Batch [140/313], Loss: 0.9986
Batch [150/313], Loss: 0.9025
Batch [160/313], Loss: 1.0476
Batch [170/313], Loss: 0.9691
Batch [180/313], Loss: 1.0763
Batch [190/313], Loss: 0.9931
Batch [200/313], Loss: 0.9606
Batch [210/313], Loss: 1.0204
Batch [220/313], Loss: 1.1037
Batch [230/313], Loss: 0.8506
Batch [240/313], Loss: 1.1421
Batch [250/313], Loss: 0.9899
Batch [260/313], Loss: 1.1238
Batch [270/313], Loss: 1.0316
Batch [280/313], Loss: 1.0851
Batch [290/313], Loss: 1.0945
Batch [300/313], Loss: 1.0426
Batch [310/313], Loss: 0.9692

Epoch 11 Results:
Time: 257.77s
Train - Loss: 0.9887, Acc: 0.6401, F1: 0.6411, Precision: 0.6437, Recall: 0.6401
Val   - Loss: 0.6608, Acc: 0.7714, F1: 0.7703, Precision: 0.7704, Recall: 0.7714
New best model saved! Validation accuracy: 0.7714
--------------------------------------------------------------------------------

Epoch [12/25]
--------------------------------------------------
Batch [0/313], Loss: 1.0541
Batch [10/313], Loss: 0.9309
Batch [20/313], Loss: 1.0391
Batch [30/313], Loss: 1.0245
Batch [40/313], Loss: 1.0462
Batch [50/313], Loss: 1.0289
Batch [60/313], Loss: 0.9483
Batch [70/313], Loss: 1.0419
Batch [80/313], Loss: 1.1164
Batch [90/313], Loss: 0.9107
Batch [100/313], Loss: 0.9723
Batch [110/313], Loss: 1.0292
Batch [120/313], Loss: 0.8011
Batch [130/313], Loss: 1.0192
Batch [140/313], Loss: 1.1355
Batch [150/313], Loss: 1.0270
Batch [160/313], Loss: 0.9807
Batch [170/313], Loss: 1.1986
Batch [180/313], Loss: 1.0591
Batch [190/313], Loss: 0.9449
Batch [200/313], Loss: 1.0378
Batch [210/313], Loss: 0.9522
Batch [220/313], Loss: 0.9331
Batch [230/313], Loss: 0.8995
Batch [240/313], Loss: 1.0661
Batch [250/313], Loss: 1.0272
Batch [260/313], Loss: 1.0981
Batch [270/313], Loss: 0.9955
Batch [280/313], Loss: 0.9434
Batch [290/313], Loss: 0.9400
Batch [300/313], Loss: 0.9337
Batch [310/313], Loss: 1.1297

Epoch 12 Results:
Time: 261.05s
Train - Loss: 0.9966, Acc: 0.6350, F1: 0.6369, Precision: 0.6405, Recall: 0.6350
Val   - Loss: 0.6634, Acc: 0.7702, F1: 0.7693, Precision: 0.7704, Recall: 0.7702
No improvement in validation accuracy for 1 epoch(s)
--------------------------------------------------------------------------------

Epoch [13/25]
--------------------------------------------------
Batch [0/313], Loss: 0.9516
Batch [10/313], Loss: 1.0521
Batch [20/313], Loss: 0.8645
Batch [30/313], Loss: 1.0840
Batch [40/313], Loss: 1.0840
Batch [50/313], Loss: 1.0924
Batch [60/313], Loss: 1.0019
Batch [70/313], Loss: 1.0480
Batch [80/313], Loss: 1.0576
Batch [90/313], Loss: 0.9850
Batch [100/313], Loss: 0.9378
Batch [110/313], Loss: 1.2115
Batch [120/313], Loss: 1.0229
Batch [130/313], Loss: 0.9360
Batch [140/313], Loss: 1.0866
Batch [150/313], Loss: 0.9443
Batch [160/313], Loss: 1.0655
Batch [170/313], Loss: 0.9581
Batch [180/313], Loss: 0.9307
Batch [190/313], Loss: 1.0226
Batch [200/313], Loss: 0.7774
Batch [210/313], Loss: 1.0014
Batch [220/313], Loss: 0.9262
Batch [230/313], Loss: 0.9092
Batch [240/313], Loss: 1.0173
Batch [250/313], Loss: 0.9155
Batch [260/313], Loss: 0.9785
Batch [270/313], Loss: 0.9167
Batch [280/313], Loss: 0.8802
Batch [290/313], Loss: 0.7936
Batch [300/313], Loss: 1.0251
Batch [310/313], Loss: 1.0019

Epoch 13 Results:
Time: 263.41s
Train - Loss: 0.9911, Acc: 0.6388, F1: 0.6391, Precision: 0.6400, Recall: 0.6388
Val   - Loss: 0.6582, Acc: 0.7716, F1: 0.7699, Precision: 0.7698, Recall: 0.7716
New best model saved! Validation accuracy: 0.7716
--------------------------------------------------------------------------------

Epoch [14/25]
--------------------------------------------------
Batch [0/313], Loss: 1.0659
Batch [10/313], Loss: 0.9290
Batch [20/313], Loss: 1.0469
Batch [30/313], Loss: 1.0599
Batch [40/313], Loss: 0.9111
Batch [50/313], Loss: 1.0869
Batch [60/313], Loss: 0.9504
Batch [70/313], Loss: 1.1130
Batch [80/313], Loss: 0.7197
Batch [90/313], Loss: 1.0075
Batch [100/313], Loss: 0.9274
Batch [110/313], Loss: 0.8949
Batch [120/313], Loss: 1.0013
Batch [130/313], Loss: 1.0290
Batch [140/313], Loss: 1.1720
Batch [150/313], Loss: 1.0263
Batch [160/313], Loss: 1.0436
Batch [170/313], Loss: 1.0265
Batch [180/313], Loss: 0.9640
Batch [190/313], Loss: 1.1649
Batch [200/313], Loss: 0.9852
Batch [210/313], Loss: 0.9943
Batch [220/313], Loss: 0.8623
Batch [230/313], Loss: 1.0629
Batch [240/313], Loss: 0.9235
Batch [250/313], Loss: 1.0001
Batch [260/313], Loss: 0.9936
Batch [270/313], Loss: 0.9081
Batch [280/313], Loss: 0.8438
Batch [290/313], Loss: 0.9627
Batch [300/313], Loss: 0.9372
Batch [310/313], Loss: 1.0339

Epoch 14 Results:
Time: 263.32s
Train - Loss: 0.9970, Acc: 0.6328, F1: 0.6333, Precision: 0.6348, Recall: 0.6328
Val   - Loss: 0.6629, Acc: 0.7705, F1: 0.7700, Precision: 0.7705, Recall: 0.7705
No improvement in validation accuracy for 1 epoch(s)
--------------------------------------------------------------------------------

Epoch [15/25]
--------------------------------------------------
Batch [0/313], Loss: 1.0606
Batch [10/313], Loss: 0.9783
Batch [20/313], Loss: 0.8968
Batch [30/313], Loss: 1.1671
Batch [40/313], Loss: 1.2002
Batch [50/313], Loss: 1.1175
Batch [60/313], Loss: 0.9631
Batch [70/313], Loss: 0.9499
Batch [80/313], Loss: 1.0790
Batch [90/313], Loss: 1.0038
Batch [100/313], Loss: 0.8817
Batch [110/313], Loss: 1.0149
Batch [120/313], Loss: 0.9227
Batch [130/313], Loss: 1.0240
Batch [140/313], Loss: 1.1334
Batch [150/313], Loss: 1.1569
Batch [160/313], Loss: 1.0776
Batch [170/313], Loss: 1.0787
Batch [180/313], Loss: 1.0384
Batch [190/313], Loss: 0.9099
Batch [200/313], Loss: 1.0884
Batch [210/313], Loss: 0.8573
Batch [220/313], Loss: 1.1335
Batch [230/313], Loss: 1.0549
Batch [240/313], Loss: 1.0325
Batch [250/313], Loss: 0.6957
Batch [260/313], Loss: 1.0694
Batch [270/313], Loss: 1.1094
Batch [280/313], Loss: 0.9214
Batch [290/313], Loss: 0.9485
Batch [300/313], Loss: 1.0774
Batch [310/313], Loss: 1.0883

Epoch 15 Results:
Time: 263.18s
Train - Loss: 0.9952, Acc: 0.6379, F1: 0.6385, Precision: 0.6404, Recall: 0.6379
Val   - Loss: 0.6626, Acc: 0.7705, F1: 0.7695, Precision: 0.7705, Recall: 0.7705
No improvement in validation accuracy for 2 epoch(s)
--------------------------------------------------------------------------------

Epoch [16/25]
--------------------------------------------------
Batch [0/313], Loss: 1.0345
Batch [10/313], Loss: 0.9925
Batch [20/313], Loss: 0.7908
Batch [30/313], Loss: 1.0261
Batch [40/313], Loss: 1.0531
Batch [50/313], Loss: 1.0050
Batch [60/313], Loss: 1.1866
Batch [70/313], Loss: 0.8275
Batch [80/313], Loss: 0.8495
Batch [90/313], Loss: 1.0643
Batch [100/313], Loss: 0.9719
Batch [110/313], Loss: 0.8994
Batch [120/313], Loss: 0.9708
Batch [130/313], Loss: 1.1227
Batch [140/313], Loss: 0.9245
Batch [150/313], Loss: 0.8447
Batch [160/313], Loss: 1.0393
Batch [170/313], Loss: 1.0160
Batch [180/313], Loss: 0.9756
Batch [190/313], Loss: 0.9527
Batch [200/313], Loss: 1.1132
Batch [210/313], Loss: 0.9774
Batch [220/313], Loss: 0.8990
Batch [230/313], Loss: 1.0551
Batch [240/313], Loss: 0.8949
Batch [250/313], Loss: 0.8342
Batch [260/313], Loss: 1.0838
Batch [270/313], Loss: 0.8841
Batch [280/313], Loss: 0.9956
Batch [290/313], Loss: 1.1950
Batch [300/313], Loss: 0.9958
Batch [310/313], Loss: 0.9105

Epoch 16 Results:
Time: 249.73s
Train - Loss: 0.9922, Acc: 0.6368, F1: 0.6373, Precision: 0.6388, Recall: 0.6368
Val   - Loss: 0.6660, Acc: 0.7699, F1: 0.7686, Precision: 0.7687, Recall: 0.7699
No improvement in validation accuracy for 3 epoch(s)
--------------------------------------------------------------------------------

Epoch [17/25]
--------------------------------------------------
Batch [0/313], Loss: 1.0279
Batch [10/313], Loss: 0.9449
Batch [20/313], Loss: 0.9985
Batch [30/313], Loss: 0.9081
Batch [40/313], Loss: 1.0195
Batch [50/313], Loss: 1.0628
Batch [60/313], Loss: 0.9030
Batch [70/313], Loss: 0.8314
Batch [80/313], Loss: 0.9548
Batch [90/313], Loss: 1.0313
Batch [100/313], Loss: 0.9694
Batch [110/313], Loss: 1.0359
Batch [120/313], Loss: 1.0075
Batch [130/313], Loss: 1.0202
Batch [140/313], Loss: 1.2164
Batch [150/313], Loss: 1.0486
Batch [160/313], Loss: 1.0130
Batch [170/313], Loss: 0.9551
Batch [180/313], Loss: 0.9891
Batch [190/313], Loss: 1.0678
Batch [200/313], Loss: 0.8488
Batch [210/313], Loss: 1.0512
Batch [220/313], Loss: 1.1401
Batch [230/313], Loss: 1.0692
Batch [240/313], Loss: 1.0941
Batch [250/313], Loss: 0.9528
Batch [260/313], Loss: 0.8676
Batch [270/313], Loss: 0.9522
Batch [280/313], Loss: 1.0683
Batch [290/313], Loss: 1.0354
Batch [300/313], Loss: 1.0597
Batch [310/313], Loss: 1.0569

Epoch 17 Results:
Time: 248.68s
Train - Loss: 0.9905, Acc: 0.6367, F1: 0.6373, Precision: 0.6389, Recall: 0.6367
Val   - Loss: 0.6612, Acc: 0.7718, F1: 0.7709, Precision: 0.7707, Recall: 0.7718
New best model saved! Validation accuracy: 0.7718
--------------------------------------------------------------------------------

Epoch [18/25]
--------------------------------------------------
Batch [0/313], Loss: 0.9528
Batch [10/313], Loss: 1.0238
Batch [20/313], Loss: 0.9322
Batch [30/313], Loss: 0.9268
Batch [40/313], Loss: 1.1405
Batch [50/313], Loss: 1.1086
Batch [60/313], Loss: 1.0450
Batch [70/313], Loss: 1.0063
Batch [80/313], Loss: 0.9419
Batch [90/313], Loss: 0.9488
Batch [100/313], Loss: 0.9220
Batch [110/313], Loss: 0.9870
Batch [120/313], Loss: 0.8552
Batch [130/313], Loss: 1.1145
Batch [140/313], Loss: 0.8302
Batch [150/313], Loss: 1.1037
Batch [160/313], Loss: 0.9221
Batch [170/313], Loss: 0.9679
Batch [180/313], Loss: 0.9980
Batch [190/313], Loss: 0.8759
Batch [200/313], Loss: 0.9898
Batch [210/313], Loss: 1.0440
Batch [220/313], Loss: 0.8894
Batch [230/313], Loss: 1.1449
Batch [240/313], Loss: 0.8953
Batch [250/313], Loss: 0.9559
Batch [260/313], Loss: 0.9980
Batch [270/313], Loss: 0.9040
Batch [280/313], Loss: 1.0633
Batch [290/313], Loss: 1.0256
Batch [300/313], Loss: 1.0976
Batch [310/313], Loss: 1.0709

Epoch 18 Results:
Time: 248.32s
Train - Loss: 0.9867, Acc: 0.6376, F1: 0.6378, Precision: 0.6384, Recall: 0.6376
Val   - Loss: 0.6522, Acc: 0.7717, F1: 0.7709, Precision: 0.7712, Recall: 0.7717
No improvement in validation accuracy for 1 epoch(s)
--------------------------------------------------------------------------------

Epoch [19/25]
--------------------------------------------------
Batch [0/313], Loss: 0.7403
Batch [10/313], Loss: 0.9835
Batch [20/313], Loss: 1.1686
Batch [30/313], Loss: 0.8669
Batch [40/313], Loss: 0.9987
Batch [50/313], Loss: 1.1569
Batch [60/313], Loss: 0.9421
Batch [70/313], Loss: 1.0400
Batch [80/313], Loss: 1.0994
Batch [90/313], Loss: 1.1255
Batch [100/313], Loss: 1.0316
Batch [110/313], Loss: 1.0479
Batch [120/313], Loss: 0.9451
Batch [130/313], Loss: 1.2656
Batch [140/313], Loss: 0.8901
Batch [150/313], Loss: 1.0419
Batch [160/313], Loss: 0.9093
Batch [170/313], Loss: 0.9874
Batch [180/313], Loss: 0.9928
Batch [190/313], Loss: 1.0575
Batch [200/313], Loss: 1.0930
Batch [210/313], Loss: 1.1453
Batch [220/313], Loss: 1.1256
Batch [230/313], Loss: 1.1067
Batch [240/313], Loss: 1.0909
Batch [250/313], Loss: 0.8984
Batch [260/313], Loss: 0.8701
Batch [270/313], Loss: 0.9241
Batch [280/313], Loss: 1.0023
Batch [290/313], Loss: 1.0251
Batch [300/313], Loss: 0.9554
Batch [310/313], Loss: 0.8939

Epoch 19 Results:
Time: 258.38s
Train - Loss: 0.9907, Acc: 0.6389, F1: 0.6408, Precision: 0.6448, Recall: 0.6389
Val   - Loss: 0.6646, Acc: 0.7711, F1: 0.7697, Precision: 0.7701, Recall: 0.7711
No improvement in validation accuracy for 2 epoch(s)
--------------------------------------------------------------------------------

Epoch [20/25]
--------------------------------------------------
Batch [0/313], Loss: 1.1202
Batch [10/313], Loss: 1.0102
Batch [20/313], Loss: 0.9393
Batch [30/313], Loss: 0.9169
Batch [40/313], Loss: 0.9123
Batch [50/313], Loss: 0.9772
Batch [60/313], Loss: 0.9804
Batch [70/313], Loss: 0.8309
Batch [80/313], Loss: 0.9773
Batch [90/313], Loss: 0.8808
Batch [100/313], Loss: 0.9128
Batch [110/313], Loss: 1.1227
Batch [120/313], Loss: 1.0637
Batch [130/313], Loss: 0.9949
Batch [140/313], Loss: 1.0383
Batch [150/313], Loss: 0.9422
Batch [160/313], Loss: 1.0606
Batch [170/313], Loss: 1.0400
Batch [180/313], Loss: 0.9868
Batch [190/313], Loss: 1.0019
Batch [200/313], Loss: 1.0196
Batch [210/313], Loss: 1.0313
Batch [220/313], Loss: 0.8628
Batch [230/313], Loss: 1.0650
Batch [240/313], Loss: 0.8291
Batch [250/313], Loss: 0.9804
Batch [260/313], Loss: 0.9698
Batch [270/313], Loss: 1.0555
Batch [280/313], Loss: 0.9888
Batch [290/313], Loss: 0.9286
Batch [300/313], Loss: 1.0159
Batch [310/313], Loss: 1.0165

Epoch 20 Results:
Time: 276.92s
Train - Loss: 0.9852, Acc: 0.6387, F1: 0.6400, Precision: 0.6426, Recall: 0.6387
Val   - Loss: 0.6606, Acc: 0.7687, F1: 0.7680, Precision: 0.7677, Recall: 0.7687
No improvement in validation accuracy for 3 epoch(s)
--------------------------------------------------------------------------------

Epoch [21/25]
--------------------------------------------------
Batch [0/313], Loss: 1.0004
Batch [10/313], Loss: 0.8520
Batch [20/313], Loss: 1.0869
Batch [30/313], Loss: 1.1507
Batch [40/313], Loss: 1.0189
Batch [50/313], Loss: 0.9803
Batch [60/313], Loss: 1.0812
Batch [70/313], Loss: 1.0336
Batch [80/313], Loss: 1.0876
Batch [90/313], Loss: 1.0069
Batch [100/313], Loss: 1.0134
Batch [110/313], Loss: 0.9897
Batch [120/313], Loss: 1.1073
Batch [130/313], Loss: 1.0991
Batch [140/313], Loss: 1.1006
Batch [150/313], Loss: 1.0095
Batch [160/313], Loss: 0.9832
Batch [170/313], Loss: 0.8195
Batch [180/313], Loss: 0.9304
Batch [190/313], Loss: 1.0153
Batch [200/313], Loss: 0.8327
Batch [210/313], Loss: 0.8216
Batch [220/313], Loss: 1.0837
Batch [230/313], Loss: 1.0756
Batch [240/313], Loss: 1.0600
Batch [250/313], Loss: 0.8797
Batch [260/313], Loss: 1.0734
Batch [270/313], Loss: 0.8823
Batch [280/313], Loss: 1.0521
Batch [290/313], Loss: 0.9838
Batch [300/313], Loss: 0.8894
Batch [310/313], Loss: 0.7764

Epoch 21 Results:
Time: 259.83s
Train - Loss: 0.9844, Acc: 0.6404, F1: 0.6421, Precision: 0.6448, Recall: 0.6404
Val   - Loss: 0.6605, Acc: 0.7715, F1: 0.7705, Precision: 0.7709, Recall: 0.7715
No improvement in validation accuracy for 4 epoch(s)
--------------------------------------------------------------------------------

Epoch [22/25]
--------------------------------------------------
Batch [0/313], Loss: 0.8827
Batch [10/313], Loss: 0.7654
Batch [20/313], Loss: 1.1721
Batch [30/313], Loss: 1.0935
Batch [40/313], Loss: 1.0946
Batch [50/313], Loss: 0.8693
Batch [60/313], Loss: 0.8834
Batch [70/313], Loss: 1.1111
Batch [80/313], Loss: 0.9916
Batch [90/313], Loss: 1.1194
Batch [100/313], Loss: 1.2247
Batch [110/313], Loss: 0.9568
Batch [120/313], Loss: 0.9093
Batch [130/313], Loss: 0.9391
Batch [140/313], Loss: 0.8421
Batch [150/313], Loss: 1.0416
Batch [160/313], Loss: 0.9823
Batch [170/313], Loss: 1.0891
Batch [180/313], Loss: 0.7569
Batch [190/313], Loss: 0.8883
Batch [200/313], Loss: 1.0438
Batch [210/313], Loss: 0.8812
Batch [220/313], Loss: 0.9876
Batch [230/313], Loss: 0.9748
Batch [240/313], Loss: 1.0126
Batch [250/313], Loss: 1.0205
Batch [260/313], Loss: 0.9779
Batch [270/313], Loss: 1.1594
Batch [280/313], Loss: 1.0487
Batch [290/313], Loss: 0.9254
Batch [300/313], Loss: 0.8728
Batch [310/313], Loss: 0.9786

Epoch 22 Results:
Time: 260.95s
Train - Loss: 0.9899, Acc: 0.6374, F1: 0.6379, Precision: 0.6397, Recall: 0.6374
Val   - Loss: 0.6553, Acc: 0.7723, F1: 0.7715, Precision: 0.7717, Recall: 0.7723
New best model saved! Validation accuracy: 0.7723
--------------------------------------------------------------------------------

Epoch [23/25]
--------------------------------------------------
Batch [0/313], Loss: 0.8440
Batch [10/313], Loss: 0.8297
Batch [20/313], Loss: 0.9377
Batch [30/313], Loss: 0.7885
Batch [40/313], Loss: 0.7964
Batch [50/313], Loss: 0.8442
Batch [60/313], Loss: 1.0198
Batch [70/313], Loss: 0.8734
Batch [80/313], Loss: 1.0109
Batch [90/313], Loss: 0.9334
Batch [100/313], Loss: 0.7866
Batch [110/313], Loss: 0.8969
Batch [120/313], Loss: 1.1629
Batch [130/313], Loss: 0.9424
Batch [140/313], Loss: 1.2204
Batch [150/313], Loss: 0.8909
Batch [160/313], Loss: 1.0580
Batch [170/313], Loss: 0.9708
Batch [180/313], Loss: 0.9381
Batch [190/313], Loss: 0.9555
Batch [200/313], Loss: 0.9121
Batch [210/313], Loss: 1.0312
Batch [220/313], Loss: 1.0411
Batch [230/313], Loss: 0.9728
Batch [240/313], Loss: 0.9894
Batch [250/313], Loss: 0.9932
Batch [260/313], Loss: 0.7796
Batch [270/313], Loss: 0.9509
Batch [280/313], Loss: 0.8469
Batch [290/313], Loss: 1.0345
Batch [300/313], Loss: 1.1543
Batch [310/313], Loss: 1.0655

Epoch 23 Results:
Time: 250.85s
Train - Loss: 0.9881, Acc: 0.6377, F1: 0.6385, Precision: 0.6404, Recall: 0.6377
Val   - Loss: 0.6565, Acc: 0.7729, F1: 0.7724, Precision: 0.7729, Recall: 0.7729
New best model saved! Validation accuracy: 0.7729
--------------------------------------------------------------------------------

Epoch [24/25]
--------------------------------------------------
Batch [0/313], Loss: 0.8924
Batch [10/313], Loss: 0.9381
Batch [20/313], Loss: 0.9643
Batch [30/313], Loss: 0.9251
Batch [40/313], Loss: 0.8998
Batch [50/313], Loss: 0.9124
Batch [60/313], Loss: 0.9576
Batch [70/313], Loss: 0.9428
Batch [80/313], Loss: 0.8642
Batch [90/313], Loss: 0.9431
Batch [100/313], Loss: 0.9061
Batch [110/313], Loss: 0.8078
Batch [120/313], Loss: 1.0325
Batch [130/313], Loss: 0.9609
Batch [140/313], Loss: 0.9981
Batch [150/313], Loss: 1.1176
Batch [160/313], Loss: 1.0396
Batch [170/313], Loss: 1.1278
Batch [180/313], Loss: 1.1086
Batch [190/313], Loss: 0.8631
Batch [200/313], Loss: 1.1120
Batch [210/313], Loss: 1.1329
Batch [220/313], Loss: 0.9942
Batch [230/313], Loss: 0.8805
Batch [240/313], Loss: 1.1390
Batch [250/313], Loss: 0.9597
Batch [260/313], Loss: 1.0072
Batch [270/313], Loss: 0.9709
Batch [280/313], Loss: 1.0421
Batch [290/313], Loss: 0.9694
Batch [300/313], Loss: 0.8493
Batch [310/313], Loss: 1.2770

Epoch 24 Results:
Time: 251.11s
Train - Loss: 0.9852, Acc: 0.6387, F1: 0.6393, Precision: 0.6406, Recall: 0.6387
Val   - Loss: 0.6597, Acc: 0.7740, F1: 0.7729, Precision: 0.7729, Recall: 0.7740
New best model saved! Validation accuracy: 0.7740
--------------------------------------------------------------------------------

Epoch [25/25]
--------------------------------------------------
Batch [0/313], Loss: 0.9180
Batch [10/313], Loss: 1.0884
Batch [20/313], Loss: 1.0280
Batch [30/313], Loss: 0.7834
Batch [40/313], Loss: 0.9793
Batch [50/313], Loss: 1.1554
Batch [60/313], Loss: 0.9052
Batch [70/313], Loss: 0.8624
Batch [80/313], Loss: 0.8793
Batch [90/313], Loss: 1.0372
Batch [100/313], Loss: 0.9569
Batch [110/313], Loss: 0.9780
Batch [120/313], Loss: 1.0859
Batch [130/313], Loss: 0.8533
Batch [140/313], Loss: 1.0004
Batch [150/313], Loss: 0.9256
Batch [160/313], Loss: 0.7721
Batch [170/313], Loss: 0.8312
Batch [180/313], Loss: 1.0489
Batch [190/313], Loss: 1.0515
Batch [200/313], Loss: 1.0825
Batch [210/313], Loss: 1.0144
Batch [220/313], Loss: 0.9563
Batch [230/313], Loss: 0.9610
Batch [240/313], Loss: 0.9218
Batch [250/313], Loss: 0.8602
Batch [260/313], Loss: 0.8772
Batch [270/313], Loss: 0.8426
Batch [280/313], Loss: 1.0731
Batch [290/313], Loss: 0.8320
Batch [300/313], Loss: 0.9821
Batch [310/313], Loss: 0.9422

Epoch 25 Results:
Time: 250.77s
Train - Loss: 0.9838, Acc: 0.6402, F1: 0.6424, Precision: 0.6464, Recall: 0.6402
Val   - Loss: 0.6592, Acc: 0.7727, F1: 0.7713, Precision: 0.7715, Recall: 0.7727
No improvement in validation accuracy for 1 epoch(s)
--------------------------------------------------------------------------------

Training completed!
Best validation accuracy: 0.7740
\nGrafik training telah disimpan sebagai '/home/manix/Documents/Semester 7/DeepLearn/Tugas-2/hasil_training_CvT.png'

Loading best model for final evaluation...

================================================================================
FINAL EVALUATION RESULTS
================================================================================
Final Validation Metrics:
Accuracy:  0.7740
F1-Score:  0.7729
Precision: 0.7729
Recall:    0.7740

Detailed Classification Report:
--------------------------------------------------
              precision    recall  f1-score   support

           0       0.78      0.82      0.80      1000
           1       0.88      0.87      0.87      1000
           2       0.70      0.67      0.69      1000
           3       0.68      0.65      0.66      1000
           4       0.71      0.69      0.70      1000
           5       0.74      0.69      0.71      1000
           6       0.78      0.88      0.83      1000
           7       0.76      0.78      0.77      1000
           8       0.86      0.83      0.84      1000
           9       0.84      0.87      0.86      1000

    accuracy                           0.77     10000
   macro avg       0.77      0.77      0.77     10000
weighted avg       0.77      0.77      0.77     10000


Generating confusion matrix...
Confusion matrix telah disimpan sebagai '/home/manix/Documents/Semester 7/DeepLearn/Tugas-2/confusion_matrix_cvt.png'

================================================================================
INFERENCE TIME MEASUREMENT
================================================================================
Warming up GPU...
Measuring inference time...

Hardware: GPU: NVIDIA GeForce RTX 3050 Laptop GPU (3.7 GB)
Total images processed: 10000
Total inference time: 48.834 seconds
Average time per image: 4.88 ms
Throughput: 204.77 images/second
Average batch time: 0.5835  0.0587 seconds

Best model saved as: /home/manix/Documents/Semester 7/DeepLearn/Tugas-2/best_cvt_model.pth

Model Summary:
- Architecture: CvT-13 (Convolutional vision Transformer) with ImageNet pretraining
- Transfer Learning: Frozen backbone + trainable classifier
- Input size: 224x224x3
- Output classes: 10
- Total parameters: 19,616,330
- Trainable parameters: 3,850
